Изображение - I = g(x, y) = {x in [x_0, x_1], y in [y_0, y_1]}
в дискр. виде: g(i, j) = {i in [1, n], j in [1, m]}

Цвет - это результат взаимодействия света, сцены и зрительной сис-мы.
Видимый цвет - это результат взаимодействия спектра излучаемого света и поверхности 

Линейная цветовая модель RGB
Основные цвета - монохроматические.

Лин. называется так как выполняется з-он Грассмана:
Пусть даны два источника света, тогда объединеный поток света есть сумма их координат.

Восстановление баланса белого:
Модель серого мира:
X'=X* (Avg / X_), где 
X=[R, G, B]
X_ = 1/N * sum X(x, y)
Avg = (R_ + G_ + B_) / 3
X' = X * Avg / X_

Гистограмма - это график распределения яркостей на изображении.
На гор. оси - щкала яркостей тонов от черного до белого 
На верт. оси - число пикселей заданной яркости 

Коррекция - преобразование яркостей, компенсирующие нежелательный эффект.
f^-1(y) = x, y - ориг. изображение

линейная коррекция: линейное растяжение диапазона, так что самый темный пиксел становится 
черным а самый белый белым.  
f^-1(y) = (y-y_min)*(255-0)/(y_max-y_min)

нелинейная коррекция:
1. гамма-коррекция: коррекция для правильного отображения на мониторе
y = c * x^gamma
2. логарифмическая: сжатие динам. диапазона при визуализации 
y = c * log(1+x)

Цветовая коррекция:
Растяжение контрастности: растянуть интенс. по каждому из каналов на весь диапазон
(X-X_min)*(255-0)/(X_max-X_min), X = [R, G, B]

Подавление шума:
Фильтрация - усреднение пиксела по окрестности вокруг него.
Веса фильтрации - наз. ядром фильтра. Это квадратная матрица.
Свертка изображения f с помощью ядра g задается как:
(f*g)[m,n] = sum k,l of f[m-k,n-l]g[k,l]
Соглашение - ядро фильтра "переворачивается" вверх дном.

Св-ва свертки:
1. filter(f_1+f_2) = filter(f_1) + filter(f_2) линейность
2. filter(shift(f)) = shift(filter(f)) инвариантность к сдвигу
вторичные св-ва:
3. f * filter = filter * f
4. f * (filter_1 * filter_2) = f * (filter_1 * filter_2)
5. f * (filter_1 + filter_2) = f * filter_1 + f * filter_2
6. f * (k*filter) = k(f * filter)
7. f * e = f

Фильтрация на краях изображение:
1. Вернуть изображение меньше размером
2. (clip filter) Дополнение черным пикселом 
3. (wrap around) "Завернуть" изображение - дополняем зацикливанием (снизу пикселями сверху в начале и т.д.)
4. (cope edge) копирование последних строк и столбцов изображения
5. (reflect across edge) отражаем недостающие строки и столбцы изображения

Простейшие фильтры:
[0,0,0; 0, 1, 0; 0, 0, 0] - ничего не меняет
[0,0,0; 0, 0, 1; 0, 0, 0] - сдвиг влево
1/9*[1,1,1; 1, 1, 1; 1, 1, 1] - усреднение
ядро гаусса sigma=3 - фильтр размытия, является фильтром низких частот (подавляет высокие частоты), 
есть смысл использовать большое ядро, по сути он позволяет разделить изображение на 
сигналы разных частот и обрабатывать их независимо
для распараллеливания процесса фильтрации по гауссу используется св-во его сепарабельности:
его ядро раскладывается в произведение двух одномерных фильтров гаусса.
Делается это так:
1. изображение раскладывается на произведение вектора столбца и строки 
2. применяем свертку по строкам (используем св-во 3)
3. применяем свертку по столбцу к результату выше

Три вида шума:
соль и перец - случайные черные и белые пиксели, подавляется медианным фильтром (из окрестности 3х3 выбирает медиану)
так же этот фильтр устраняем тонкие линии\окружности
импульсный - случайные белые пиксели
гауссов - колебания яркости, распред. по норм. з-ну, подавляется гауссовым фильтром 

При сглаживании теряются высокие частоты.
Чтобы повысить резкость нужно из оригинала "вычесть" сглаженное изображение (получить высокие частоты)
и добавить полученный результат к оригиналу с некоторым коэффициентом 

Это фильтр unsharp он повышает резкость:
f+alpha*(f-f*g)=f*((1+alpha)e-alpha*g)

Компенсация разности освещения:
Положим что изображение формируется произведением объекта с картой освещенности:
I(i,j) = r(i,j)*l(i,j)
алгоритм Single scale retinex:
1. получить изображение освящения с помощью фильтра Гаусса
l'(i,j) = G*I(i,j)
2. восстановить изображение по формуле
r' = log(I(i,j)) - log(l'(i, j))
многомасштабный вариант: как правило 3 масштаба и веса одинаковые (1/3)
r' = sum k of w_k*(log(I(i,j)) - log(G_k(i,j)*I(i,j)))

Метрики качества изображений:
1. среднеквадратичная ошибка
MSE = 1/N sum i of (x_i - y_i)^2 
2. пиковое отношение сигнал\шум 
PSNR (в dB) = 10 *(2*lg(M) - lg(MSE)), где M макс значение яркости пикселя 

спецэффекты:
1. Тиснение
фильтр ([0,1,0;1,0,-1;0,-1,0] ) + сдвиг яркости + нормировка
2. Цифровой негатив
X'=255-X, X=[R,G,B]
3. светящиеся края
медианный фильтр + выделение краев + фильтр "максимума" (максимум между оригиналом и выделенным фильтром)
4. Перенос(сдвиг)\поворот
5. "Волны" (сдвиг по синусоиде)
6. Эффект стекла, случайный сдвиг
---------------------------------------------------------------------
СОПОСТАВЛЕНИЕ ШАБЛОНОВ:
1. фиксация объекта
2. Описать его изображением (шаблоном)
3. Задача - найти объект в изображении
4. Ограничить возможные преобразования объекта 
5. Поиск объекта в изображении по пиксельном сравнением с шаблоном

метрики для поиска шаблона:
Sum of abs dif (SAD) |x-y|
Sum of square dif (SSD) (x-y)^2
Cross-correlation (CC) a*b

для поиска
SAD, SSD -> min
CC -> max

освещенность нужно нормализовать или выравнять
нормализация освещенности:
I' = (I-I_avr)/||I-I_avr|| норм пиксель в диапазоне [-1;1], где 
I_avr = 1/N sum i, j of I(i,j)
||I|| = sqrt(sum i,j of I(i,j)**2) - норма интенсивности 

- метода:
ищет один конкретный объект а не все класс объектов
работает на практике плохо
+ метода:
эффективно применяется в видео (сначала хорошим методом находиться объект, потом так как 
вряд ли он сильно меняется от кадра к кадру ищем его сопоставлением - это быстрее чем искать 
объект на каждом кадре с 0)
---------------------------------------------------------------------
ВЫДЕЛЕНИЕ ГРАНИЦ:
цель - выделить самую значимую для поиска часть изображения,
для обобщения и прироста производительности сопоставления
край - это точка резкого изменения значений ф-ции интенсивности
изображения, т.е. экстремум данной ф-ции.
градиент будет направлен в сторону наибольшего изменения интенсивности
заменим частные производные разностным их приближением
т.к. она линейная и инвариантна к сдвигу то мб является рез-ом свертки 
т.о. фильтр [-1, 1] будет находить производную f по x с dx = 1

приближенно вычислить производную по направлению позволяют фильтры ниже:
1. Робертс:
[-1 0; 0 1], [0 -1; 1 0]
2. Превитт
[-1 -1 -1;0 0 0;1 1 1], [-1 0 1;-1 0 1;-1 0 1]
3. Собель - топ
[-1 -2 -1;0 0 0;1 2 1], [-1 0 1; -2 0 -2; -1 0 1]

шум крайне негативно влияет на вычисление производных, от него необходимо избавляться.
причем можно сэкономить 1 операцию - сначала вычислить производную фильтра и использовать ее 
при фильтрации.

не стоит забывать что чем больше размерность ядра тем больше размытие - края будут тоже размываться

критерии качества детектора краев:
1. надежность - выдает мало пропущенных краев и ложных
2. точная локализация - найденный край должен быть максимально близко к истинному краю
3. единственный отклик - выдача одной (в идеале) точки для одной точки истинного края 
4. связанность - какие пиксели принадлежат одной линии края

детектор Canny:
1. фильтрация изображение производной от фильтра Гаусса
2. поиск норму и направление градиента 
3. выделение локальные максимумы и утоньшение в несколько пикселей до 1
4. гистерезис - связывание краев и обрезание по порогу (нижний порог для продолжения кривых, верхний для их инициализации)
 
минусы Canny:
одинаково определяет края не придавая им семантики (более важные края могут быть заметны хуже или вовсе пропускаться)

метрики для сравнения краев шаблона A и изображения B:
1. Чамфер - сумма отклонений края шаблона от края картинки
ChDist(A, B) = sum a in A of min by b in B of ||a-b||
нужна нормализация
симметричная
2. Хаусдорф - макс отклонение края шаблона от края картинки 
HausDist(A, B) = max a in A of min b in B of ||a-b||
ненужна нормализация
несимметричная

Distance transform:
Для каждого пикселя вычисляется расстояние до ближайшего пикселя края, для краев оно 0
применение: 
1. совместив шаблон и карту DT вычислим сумму элементов DT которые попали на края 
шаблона - это будет значение ошибки
2. поиск осей объекта ("скелета") - если визуализировать DT то чем ярче пиксель тем дальше он от границ 

В итоге суммарно метод сопоставления шаблонов:
Подходит тогда когда объекты фиксированные и модель преобразований не сложная
пример: цифры\буквы, поиск объектов на аеро\космических снимках
Сами метода сопоставления не быстрые и требуют ускорений
---------------------------------------------------------------------
БИНАРИЗАЦИЯ ИЗОБРАЖЕНИЯ - преобразование изображения в изображение, в котором фон имеет значение 0 
а объекты значение 1

пороговая фильтрация - 0 если яркость ниже порога, 1 иначе или наоборот

порог можно определить с помощью гистограммы в тех случаях, в которых изображение двух цветов
фон однотонный и занимает бОльшую часть изображения:
	1. сглаживание гистограммы
	2. поиск ячейки гистограммы с макс значением h_max - средний цвет фона
	3. поиск на той стороне гистограммы, которая не относиться к объекту (если фон ярче объектов то справа от h_max
	иначе слева), яркости h_p, кол-во пикселей с яркостью >= или <= (правее если фон ярче) h_p есть p% (мб 5) от пикселей яркости 
	которых >= или <= (правее если фон ярче) h_max
	4. пересчитать порог T = h_max - (h_p - h_max) = 2*h_max - h_p

однако если освещение не равномерное, то метод не применим.
в таких случаях нужно либо его выравнять либо применить адаптивную бинаризацию.

Адаптивная бинаризация:
Для каждого пикселя в его окрестности заданного радиуса высчитывается индивидуальный порог T.
Если I(i, j) > T(i, j) + C то 1, иначе 0
T = mean | median | (min+max) / 2

Если грамотно подобрать радиус и постоянную, то можно решить и задачу выравнивания освещения и бинаризации.

Когда не получается устранить шум или получить достаточную контрастность, нужно 
применять методы подавления шума на основе окрестностей пикселов.

Операции математической морфологии:
Пусть A объект обработки, а B инструмент
	1. Сужение (-) - логическое И
с увеличением размера и структуры инструмента можно удалить почти весь шум
однако размеры объектов сузятся 
	2. Расширение (+) - логическое ИЛИ, если хотя бы один пиксел из B совпал в окрестности то 1, иначе 0

коммутативный з-он:
A(+)B = B(+)A
A(-)B = B(-)A
ассоциативный з-он:
A(+)(B(+)С) = (A(+)B)(+)С
A(-)(B(-)С) = (A(-)B)(-)С

удачно подобрав размерность и структуру инструмента
можно решить следующие задачи:
шумоподавление
выделение границ объекта
выделение осей (скелета) объекта 
выделение сломанных зубьев на изображении шестерни

	3. Открытие - open(A, B) = (A(-)B)(+)B
тоже удаляет шум но не уменьшает объекты
недостаток - границы объектов сглаживаются 
	4. Закрытие - close(A, B) = (A(+)B)(-)B
удаляет шум на объектах

Мат морф не помогает если шум на бинарном изображении слишком сильный
тогда применяют медианный фильтр и мб после него мат морф если надо
---------------------------------------------------------------------
ВЫДЕЛЕНИЕ СВЯЗАННЫХ ОБЛАСТЕЙ 

связанная область - мн-во пикселей у каждого пикселя которого есть хотя бы 
один сосед, принадлежащий данному мн-ву.

4-связанность - соседи это все пиксели смежные по гориз или веритк
8-связанность - соседи это все пиксели смежные по гориз или веритк или диагонали

разметка связ областей - это размеченное изображение полученное из бинарного, в котором
пиксели каждого объекта равны его номеру 

метод последовательного сканирования:
будем последовательно обходить бинарное изображение слева-направо сверху-вниз
*С
BA

if A == 0: # фон
	continue
if B <= 1 and C <= 1:
	A = new_number
	new_number += 1
elif B > 1 xor C > 1:
	A = max(B, C)
else:
	if B == C:
		A = B
	else:
		A = min(B, C) # например
		table.push(A <=> B <=> C)

после всех итерация выше получаем выделенные связанные области + таблицу эквивалентности отметок 
---------------------------------------------------------------------
АНАЛИЗ ВЫДЕЛЕННЫХ ОБЛАСТЕЙ

числовые признаки областей:
1. геометрические
	главным образом интересуют инвариантные - то есть для объектов разных размеров но одной формы 
	значение признака не отличается
	I - бинарное!
	1. площадь S - кол-во пикселей в компоненте
	2. центр масс - пиксель с индексами (sum x of sum y of x*I(x,y) / S, sum x of sum y of y*I(x,y) / S)
		нужен в определении центрального момента 
		m[i,j] = sum (x,y) in S of (x-x*)^i * (y-y*)^j * I(x,y)
	3. компактность - отношение кв-та периметра к площади, где периметр это кол-во пикселей составляющих границу компоненты 
		это св-во инвариантно
		варианты подсчета пикселей периметра:
			внутренняя граница - пиксель в компоненте и хотя бы один его сосед НЕ в ней 
			внешняя граница - пиксель в НЕ компоненте и хотя бы один его сосед в ней 
			так же подсчет зависит от типа связанности компонент 
			
			получить контур объекта в бинарном изображении можно операциями ниже:
				1. внутренние оконтурирование C_in = A-(A(-)B)
				2. внешнее оконтурирование C_out = (A(+)B)-A
	4. ориентация главной оси инерции
		к повороту не является инвариантным , но иногда все равно полезно
		угол наклона главной оси = 0.5*arctan(2*m_11/(m_20-m_02))
	5. удлиненность (эксцентриситет) - приближение компоненты к норм распределению с не нулевой матрице ковариации 
		это св-во инвариантно, т.к. является отношением фокусного расстояния к большой полуоси эллипса 	
		elong = m_20+m_02+sqrt((m_20-m_02)^2 + 4*m_11^2) / (m_20+m_02-sqrt((m_20-m_02)^2 + 4*m_11^2))
2. фотометрические
	по исходному изображение для компонент в бинарном изображении 
	можно выделить признаки ниже:
	1. средняя яркость\цвет
	2. гисторама распределения яркости\цвета
	3. дисперсия яркостей\цвета

использование признаков:
1. подбор значений для классов объектов вручную - долго
	выписать наблюдения
	из них составить решающие правило
2. подбор диапазонов значений графически - нужна база и кол-во признаков усложняет 
	собрать базу:
		где только объекты obj_i
		где только шум
	строя графики пытаться найти закономерности
3. машинное обучение
	современный стандарт, причем от двух выше методов может работать даже при огромном кол-ве признаков
---------------------------------------------------------------------
ЛОКАЛЬНЫЕ ОСОБЕННОСТИ 

локальная особая точка - это точка отличающаяся от всех точек в некоторой окрестности

требования к особенностям
	1. повторяемость - особенность находиться в том же месте сцены не зависимо от освящения и точки обзора
	2. значимость - особенность имеет уникальное описание
	3. компактность - кол-во особенностей много меньше кол-ва пикселей 
	4. локальность - особенность занимает малую область изображения (не чувствительность к перекрытиям 
		объекта поиска другими объектами)

виды особенностей:
	1. углы - в области вокруг угла у градиента изображения два доминирующих направления 
	углы хорошо повторимы и различимы
	2. блобы - область изображения, в которой некоторые свойства, такие как интенсивность 
	или цвет, приблизительно постоянны
	3. область - примерно аналог блоба 

Детектор Лапласиана (блобы):
	для каждого пикселя вычисляется сверта с Лапласианами разного масштаба 
	и так как его максимум достигается при sigma=r/sqrt(2) вычислить характерный размер r окрестности 
	среди всех точек нужно выбирать устойчивые, то есть те макс которых ярко выражен 
	
	в многомасштабном варианте на разных масштабах свертываем изображение и ищем макс в 3 измерениях
	
	для повышения эффективности лапласиан заменяется разностью двух гауссианов 

Детектор Харриса (углы):
	изменение яркости в окрестности:
	E=sum x,y of w(x,y) [I(x+u,y+v)-I(x,y)]^2
	веса чаще всего либо одинаковые либо норм. распределение
	для малых u, v
	E(u,v) ~= [u v] M [u; v]
	M = sum x,y of w(x, y) [I_x^2, I_x*I_y; I_x*I_y, I_x*I_y] - матрица частных производных
	если одно из собственных значений близко к 0,то это не угол 
	Пусть R=detM-k(traceM)^2=lambda_1*lambda_2-k(lambda_1+lambda_2)^2, k in [0.04, 0.06]
	Тогда если |R| < eps то плоская область, 
			R < 0 то край
			R > 0 угол

	алгоритм Харриса
		1. Предварительно отфильтровав по Гауссу, вычислить градиент изображения в каждом пикселе
		2. Вычислить матрицу M по окну вокруг каждого пикселя 
		3. Вычислить отклик угла R
		4. Отрезать по порогу R
		5. Найти лок макс функции отклика по окрестности заданного радиуса 
		6. Выбрать N самых сильных лок макс

	инвариантость к преобразованиям:
		1. частичная к изменению освещенности - лок макс R не меняется одного ее значение увеличивается
		2. полная к повороту 
		3. НЕ инвариантен к масштабированию

Детектор Харриса-Лапласиана (углы):
	по изображению применяется харрис
	по масштабу лапласиан 

	в отличии от оригинального детектора инвариантен к масштабированию

проблема выбора точек в том что их желательно выбирать равномерно, однако сильные отклики сосредотачиваются иначе 

решением является адаптивный выбор точек по заданному радиусу:
	1. будем идти по точкам в порядке качества 
	2. для каждой точки выкинем из списка всех соседей в окрестности 
	3. если кол-во оставшихся точек больше, выберем радиус по меньше иначе по больше и так пока не найдем нужное кол-во

Детектор IBR (области):
	идти от лок экстремума яркости по лучам, считая f(t)=|I(t)-I_0|/[1/t int from 1 to t of |I(t)-I_0|],
	завершение при достижении пика f 

Детектор MSER (область):
	задать порог яркости 
	провести сегментацию по порогу 
	извлечь области 
	для каждой области найти порог при котором рост площади минимален
	описать вокруг области эллипс 

дескриптор - вектор признаков точки 

св-ва дескриптора:
	1. специфичность - разным точкам разный дескриптор
	2. локальность - зависит только от небольшой окрестности 
	3. инвариантность к освещению и преобразованиям
	4. простота вычисления

алгоритм SIFT:
	1. определить положение и масштаб особенности детектором блобов (Лапласиан, разность гауссианов)
	2. определить доминантную ориентацию по градиенту 
	3. использовать статистику по направлению градиента 

	устойчив к изменениям освещенности, небольшим сдвигам, повороту, масштабу

	вычисление ориентации:
		нужно найти направление градиентов пикселей окрестности 
		и построить их гистограмму направлений (угол направления [0;2pi]) 
		глоб максимум гистограммы будет соответствовать доминантному направлению 
		повернем окрестность так что бы дом градиент был направлен вверх 
		или "вырежем" прямоугольную область (rotation invariant frame) так что бы 
		дом градиент в ней был направлен вверх
		если макс по гистограмме несколько то "вырежем" несколько рамок (две) с разной ориентацией 

	таким образом мы выбрав rotation invariant frame для особенности 
	можем привести ее к некоему стандартному размеру 

	вычисление дескриптора:
		вычислить градиент в каждом пикселе
		построить гистограмму направлений градиентов по прямоуг. областям 
		вклад пикселей взвешивать по гауссиане с центром в центре окрестности
		по стандарту сетка 4х4 и в каждой гистограмма с 8 ячейками (вверх,вниз,вправо,влево+диаг)
		дескриптор есть вектор 128 длиной

сопоставление особенностей:
	сгенерировать пары-кандидатов - для каждой особенности первого изображения найти 
	несколько похожих по метрики на другом изображении

	выбор пар осуществляется приближенно с помощью структур данных (kd-tree, vocabulary trees, хеш-таблицы)

	спец метрики для дескрипторов:
		1. sum i 1 to n of min(d_1[i], d_2[i])
		2. (топ) sum i 1 to n of (d_1[i] - d_2[i])^2 / (d_1[i] + d_2[i])

	фильтрация пар-кандидатов:
		сравниваем расстояние первой ближайшей особенностью со второй ближайшей по метрики
		отношение будет большим для не оч "выделенных" особенностей 
		порог 0.8 хорошо себя показывает 

	MND(x,y) = NN(x,y)+NN(y,x), N(a,b) = 1 если b ближайший (по евклидову расст например) к a сосед, 
	если k-ый по близости то N(a,b) = k 
---------------------------------------------------------------------
ОЦЕНКА ПАРАМЕТРОВ МОДЕЛИ 

нахождение параметров прямой аппроксимирующую набор точек:
если нет ошибок в координатах:
1. минимум кв-ов расстояний от точек до прямой
2. макс правдоподобия l=argmax i of P[{(x_i, y_i)}|l]

если они присутствуют только по y и при этом незав+распред нормально и одинаково:
	модель: y=a*x+b, x_i=X, y_y=Y+eps, eps ~ N(0, sigma^2)
	метод наименьших кв-ов
	l=argmax (a, b) of sum i of P[{(x_i, y_i}|a,b]=argmin (a,b) of sum i of (y_i-a*x_i-b)^2
	для минимизации нужно решить ур-ние 
	X^T*X*B=X^T*Y, где Y=[y_1; ...; y_n], X=[x_1, 1; ...; x_n, 1], B=[a; b]
	* ур-ния такого типа XB=Y называются нормальными 

если они присутствуют и по х и по у:
	модель: точки зашумлены норм шумом в направлении перпен. к линии
	полные наименьшие кв-ты: расстояние от (x_i, y_i) до прямой a*x+b*y=d
	[x;y]=[u;v]+eps*[a;b], где [u;v] точка на линии, eps ~ N(0, sigma^2), [a;b] нормаль к прямой
	l=argmax (a, b, d) of sum i of P[{(x_i, y_i}|a,b,d]=argmin (a, b, d) sum i of (a*x_i+b*y_i-d)^2
	=> d = a/n * sum i of x_i + b/n * sum i of y_i= a * x' + b * y'

	для минимизации нужно решить ур-ние
	(U^T*U)*N=0, при условии ||N||^2=1, его решением будет
	собственный вектор U^T*U который соответствует минимальному собственному значению
	для его поиска нужно юзнуть SVD разложение 

	*A=U*D*V^T, U,V ортогон., D диагональная сост. из сингулярных чисел, (над полем R)
	Неотрицательное вещественное число σ называется сингулярным числом матрицы M 
	тогда и только тогда, когда существуют два вектора единичной длины u и v такие, что:
	M v = σ u ,  и M^T u = σ v 
	Такие векторы u и v называются, соответственно, левым сингулярным вектором и правым 
	сингулярным вектором, соответствующим сингулярному числу σ .

	так как A^T*A=V*D*U^T*U*D*V^T=V*D^2*V^T
	то сингулярные числа это sqrt собств. значений A^T*A

	пусть нужно решить Ap=0, ||p||=1, тогда
	A=U*D*V^T
	нужно мин. ||U*D*V^T*p||=||D*V^T*p||, ||V^T*p||=||p||
	нужно мин. ||D*V^T*p||, при ||V^T*p||=1
	положим y=V^T*p
	нужно мин. ||Dy||, при ||y||=1
	D - столбцы упорядоченны по убыванию
	=> y = [0; 0; ...; 1], тогда p есть последний столбец V

если присутствуют точки не принадлежащие прямой (выбросы):
	М-оценки: 
		будем уменьшать влияние "далеких" точек
		возьмем параметризацию:
		x*cosQ+y*sinQ=R
		(Q, R) = argmin (Q, R) of sum i of (x_i*cosQ+y_i*sinQ-R)^2 =
		= argmin (Q, R) of sum i of f(eps_i), eps_i=x_i*cosQ+y_i*sinQ-R

		нужно мин sum i of f(r_i(x_i, (Q, R)); sigma), где r_i невязка(ошибка),
		f - робастая функция с масштабом sigma (при малых u как кв-ат расстояния, при больших выравнивается)

		ф-ция Тьюки: f(eps) = K^2/6[1-(1-(eps/K)^2)^3] if |eps| <= K else K^2/6, например K=4.685
		ф-ция Коши: f(eps) = c^2/2*log(1+(eps/c)^2), например c=2.385

		итеративные перевзвешенные наименьшие квадраты:
			1. нач приближение с помощью МНК (Q_0, R_0)
			2. для (Q_t-1, R_t-1) посчитать оценку шума sigma_t = 1.4826 median_i |r_i(x_i, (Q_t-1, R_t-1))|
			3. w_i = f'(eps_i/sigma)/(eps_i/sigma) 
				1-(eps_i/(sigma*K))^2 if |eps_i/sigma| <= K else 0 - Тьюки
				1/(1+(eps_i/(c*sigma))^2) - Коши
			4. с помощью взвеш. МНК получить (Q_t-1, R_t-1)
			5. пока ||[Q_t, R_t]-[Q_t-1, R_t-1]|| > eps` повторять 2,3,4

		минусы:
			нужно хорошее 0 приближение 
			нужен подбор весов

	RANSAC (random sample consensus):
		будем проводить оценку не по всей выборке а по ее части без выбросов 
		получим такую выборку случайно за несколько попыток
		выборка будет содержать минимальное кол-во точек необходимое для оценки модели
		например для прямой 2 точки, для окружности 3  и т.д. 

		выполняем n раз
		построение выборки 
		построение гипотезы по выборке 
		оценка степени согласия гипотезы и набора исходных данных
		выбор наилучшей гипотезы 
		уточнение гипотезы по всем "хорошим" данным

		R(Ethna) = sum i of p(eps_i(Ethna)^2), p(eps_i^2) = 1 if eps_i^2 <= T^2 else 0
		eps_i(Ethna) - невязка точки и гипотезы

		адаптивная версия:
		N=inf, sample_count=0
		while N > sample_count:
			построение выборки, гипотезы по выборке, оцениваем кол-во "хороших" точек
			e = 1 - number_good/number_total
			N = log(1-p)/log(1-(1-e)^s), s = кол-во эл-ов в выборке, p=вер-ть получить хор выборку (0.99)
			sample_count += 1

		недостаток этого метода в том, что результат очень сильно зависит от порога T
		нивелирует это его модификация M-SAC в которой 
		R(Ethna) = sum i of p(eps_i(Ethna)^2), p(eps_i^2) = eps_i^2 if eps_i^2 <= T^2 else T^2

		метод легко обобщается на многие модели
		например по мимо прямой можно скать и окружность 
		отличие только в размере выборке и R(Ethna) 

	приложение - фильтрация ложных соответствий между M' и M:
	используем модель преобразования H из M в M'
	оценим ее с помощью RANSAC 
	отфильтруем выбросы по модели 
	уточнить модель по всем оставшимся точкам

	вычисления аффинного преобразования:
		пусть (x_i, y_i) (x_i', y_i') сопоставленные особые точки двух изображений
		[x_i'; y_i'] = [m_1, m_2; m_3, m_4] * [x_i; y_i] + [t_1; t_2]

		[x_0, y_0, 0, 0, 1, 0; 0, 0, x_0, y_0, 0, 1;
		x_1, y_1, 0, 0, 1, 0; 0, 0, x_1, y_1, 0, 1;
		x_2, y_2, 0, 0, 1, 0; 0, 0, x_2, y_2, 0, 1] * [m_1; m_2; m_3; m_4; t_1; t_2] = [x_0'; y_0'; x_1'; y_1'; x_2'; y_2']

		нужно три соответствия для оценки преобразования 
		применим RANSAC для получения преобразования 

	схемы голосования:
		Пусть каждый элемент данных голосует за те модели, которым он удовлетворяет
		Гипотезы с максимальным числом голосов побеждают
		Надеемся, что выбросы не будут голосовать согласовано
		Пропущенные данные не имеют значения, пока хватает голосов имеющихся данных за правильные модели

		преобразование Хафа:
			1. H - нулевая матрица
			2.для каждой точки края:
				for a in range(180):		
					r = x*cosa + y*sina
					H(a, r) += 1
			3. найти лок макс H 
			уменьшить время работы можно используя градиент 
			2. для каждой точки края:
				a = grad orient (x, y)
				r = x*cosa + y*sina
					H(a, r) += 1

---------------------------------------------------------------------
КЛАССИФИКАЦИЯ ИЗОБРАЖЕНИЙ

рассмотрим изображения на которых присутствует 1 объект определенного класса

задача классификации изображений:
1. есть ли на изображении объект заданного класса?
2. относиться ли изображение к заданному классу?

задача машоб:
	Есть обучающая выборка в которой каждый элемент описывается набором признаков x 
	для каждого которого известен ответ у.
	Требуется сконструировать функцию f(x) (решающее правило\классификатор) которая 
	выдает ответ y для любого вектора признаков x 
	Она должна "хорошо" работать на новых данных.

бинарная классификация:
	Дана обвыборка X, где (х_i, y_i) in R^m*Y, Y={-1, 1}.
	Объекты не зависимые и взяты с определенным распределением.
	Цель- для всех новых x оценить значение argmax P(y|x).
многоклассовая классификация:
	аналогично только Y={1,...,K}
регрессия:
	Y=R и объекты взяты из неизвестного распределения и нужно оценить argmax E(y|x)
кластеризация:
	даны только векторы признаков, известно что они разбиты по кластерам на основе данной 
	метрики

формально:
	1. будем выбирать функции f из параметрического семейства F
	2. пусть L(f(x), y) - ф-ция потерь 
	3. задача обучения состоит в том, что бы найти набор параметров классификатора f, при котором 
	потери на новых данных будут минимальны 
	4. "метод классификации" = парам. семейство F + алгоритм оценки параметров по обучающей выборке 

эмпирический риск:
	пусть X^m обвыборка, тогда R_emp(f, X^m)=1/m * sum i from 1 to m of L(f(x_i), y_i)
	=> f = argmin f in F of R_emp(f, X^m)

явление переобучения:
	когда гипотеза хорошо описывает не св-ва объектов в целом, а только объектов из обучающей выборки 
	происходит когда: слишком "сложная" модель, шум в данных, плохая обвыборка 

принцип структурной минимизации риска:
	мы должны выбирать самую простую модель из достаточно точных (следствие из теории Вапника-Червоненкиса)
	пусть есть послед. F_1 subset F_2 subset .... subset F_h = F. 
	должны выбрать семейство с минимальной сложностью, но с достаточной точностью

удерживание:
	пусть дана обвыборка с известными ответами 
	разобьем его на две не пересекающиеся части 
	одну часть будем использовать для обучения а другую для контроля 
	=> P(f(x) != y) ~ P(f(x) != y|X_cont)

	св-ва метода:
		1. быстро и просто рассчитывается
		2. некоторые "сложные" векторы признаков могут полностью попасть только в одну из выборок 
		таким образом оценка ошибки будет смещенной 

скользящий контроль:
	разделим обвыборку на d не пресекающихся частей и поочередно будет использовать одно из
	них для контроля а оставшиеся для обучения 
	результат считается как средняя ошибка по всем итерациям 
	св-ва метода:
		1. в пределе равен общему риску 
		2. каждый вектор признаков будет один раз присутствовать в контрольной выборке 
		а так же будет в обучении
		3. некоторые "сложные" векторы признаков могут полностью попасть 
		только в один из сегментов и оценка ошибки будет смещенной

пусть есть основной класс 
ошибка 1 рода - вер-ть принять основной класс за вторичный (пропуск искомого объекта)
ошибка 2 рода - вер-ть принять вторичный класс за основной (принятие искомого объекта за "фон")
 
их важно разделять при несбалансированности классов (когда объектов одного из классов очень мало и 
других кратно больше)

чувствительность - вер-ть дать правильный ответ на пример основного класса 
избирательность - вер-ть дать правильный ответ на пример вторичного класса 

ROC (receiver operating characteristic) кривая - отображает зависимость чувствительности от ошибки 2 рода 
для различных значений параметра (который регулирует чувствительность) строится таблица ошибок не на обучающей выборке 
по таблице строиться наобер точек на пл-ки чувствительность/ложное соответствие и приближается кривой 
пл-дь под кривой - чем больше тем метод качественней 

линейный классификатор:
	найдем лин (гиперпл-ть) функцию и разделим положительные и отрицательные примеры 
	x_i*w+b>=0 - положительные
	x_i*w+b<0 - отрицательные

метод опорных векторов:
	найдем гиперпл-ть, макс. "отступ" между положит и отрицательными примерами 
	параметры гиперпл-ти всегда можно задать таким образом, что
	x_i*w+b>=1 - положительные (y_i=1)
	x_i*w+b<=-1 - отрицательные (y_i=-1)
	тогда опорными векторами назовем вектора удвл. условию: x_i*w+b=+\-1
	расстояние от точки до гиперпл-ти |x_i*w+b|/||w||
	=> отступ равен 2/||w||, т.к. |x_i*w+b|=1

	нужно максимизировать 2/||w|| и правильно классифицировать все данные 
	т.о. получилась квадратичная оптимизационная задача:
	минимизация 1/2*w^T*w при условии y_i*(w*x_i+b) >= 1
	решается методом множителей Лагранжа

	решение: w = sum i of alpha_i * y_i * x_i, где alpha_i != 0 только для опорных векторов 
	b = y_v-w*x_v - для любого опорного вектора 

	на практике нужно ввести доп переменные, и решать задачу макс. отступа так что бы ложно 
	классифицированных точек было минимальное кол-во:
	минимизация 1/2*w^T*w + С sum i of eps_i
	при условии y_i*(w*x_i+b) >= 1-eps_i, где C параметр регуляции 

нелинейный метод опорных векторов:
	нужно отобразить исходное пр-во параметров на многомерное пр-во 
	где обучающая выборка линейно разделима 
	трюк ядра: вместо прямого вычисления преобразования phi(x) выделим его
	ядровую ф-цию K(x_i, x_j)=phi(x_i)*phi(x_j)
	для корректности матрица K(x_i, x_j) должна быть неотриц. определенной 
	с помощью ядра сможем построить нелин. решающую ф-цию в исходном пр-ве 
	sum i of alpha_i*y_i*K(x_i, x) + b

использование МОВ:
	1. выбрать признаки для изображения 
	2. выбрать ядро для этого вектора признака
	3. вычислить матрицу значений ядра для каждой пары примеров из обучающей выборки 
	4. получить из матрицы веса и опорные вектора (библ. SVN)
	5. во время вывода вычислить значения ядра для тестового образца и каждого опорного вектора 
	и взять взвешенную сумму для получения решающей ф-ции 

формулировки для многоклассового случая у МОВ нету
однако его все равно можно использовать для этой задачи
1. один против всех
	обучение: обучаем МОВ для каждого класса против всех остальных 
	вывод: применим все МОВ к образцу и отнесем его к классу по наиболее достоверному решению
2. один против одного 
	обучение: обучим МОВ для каждой пары классов
	вывод: каждый МОВ голосует за свой класс, выбор класса с наибольшим числом голосов

плюсы МОВ:
1. много библиотек
2. мощный и гибкий
3. работает оч хорошо даже при малых обвыборок
минусы МОВ:
1. нет прямого многоклассового метода
2. время вычисления, память 

визуальное слово - часто повтор. фрагмент изображения 
визуальный словарь - набор фрагментов, часто повторяющихся в коллекции изображений 
для его составления нужно:
	составить большой список всех фрагментов по всей коллекции 
	разделить весь список на похожие группы
	будем считать все фрагменты в одной группе "экземплярами" одного и того же слова 

метод "мешок слов":
	1. извлечь особенности 
	2. обучить визуальный словарь
	3. сопоставляем особенностям номер 
	4. описываем изображение гистограммой (частота слова\номер слова)

	варианты извлечение особенностей:
	регулярная сетка - разбить изображение сеткой на фрагменты 
	особые точки - брать окрестность особых точек 

	для каждого фрагмента посчитать дескриптор SIFT 
	получен набор неупорядоченных векторов признаков 

	таким образом получается задача кластеризации 

	кластеризация К-средними:
	минимизируем D(X, M) = sum k (cluster) of sum i (point in cluster_k) of ||x_i-m_k||^2
	1. случайно инициализируем K центров кластеров 
	2. повторяем до сходимости
	2.1 назначить каждую точку ближайшему центру кластеру  
	2.2 пересчитаем центр каждого кластера как среднее всех назначенных точек 

	св-ва метода:
	1. всего один параметр - кол-во кластеров 
	2. зависит от начального приближения (иногда полезно несколько раз его применить 
	и выбрать лучший вариант)
	3. не учитывает строение кластеров 
	4. часто применим 

	для каждого фрагмента можно найти слово из словаря - ищем ближайшее по дескриптору

	вектор признак у изображения будет гистограмма (частота слова\номер слова)
	используем МОВ с ядром:
	I(h_1, h_2) = sum i 1 to n of min(h_1[i], h_2[i])
	или 
	K(h_1, h_2) = exp(-1/A * D(h_1, h_2)^2)
	где D(h_1, h_2) = sum i 1 to n of (h_1[i] - h_2[i])^2 / (h_1[i] + h_2[i])
---------------------------------------------------------------------
ПОИСК И ЛОКАЛИЗАЦИЯ ОБЪЕКТОВ 

метод скользящего окна:
	сведем задачу поиска и локализации объектов к задаче классификации изображений 
	будем проходиться по данному изображению рамкой в надежде что объект в нее попадет 

поиск "пешеходов":
	1. будем использовать скользящее окно 64х128 пикселей, если окно больше то масштабируем 
	его до указанного размера 
	2. вычислим градиенты 
	3. каждое окно разобьем на ячейки 8х8 пикселей
	4. опишем такие ячейки гистограммами по 8 направлениям как в SIFT (HOG, histogram oriented gradient)
	5. для нормализации вместо деления на 64, будем выделять блоки 2х2 размера с перекрытиями 
	6. Получается дескриптор длинной в 4096 
	7. обучим на них SVM бутстраппингом:
		7.1 выберем отрицательные примеры случайно и вручную отметим верные
		7.2 обучаем SVM
		7.3 применяем к данным 
		7.4 добавим ложные обнаружения к выборке 
		7.5 повторить 

	для увеличения исходного набора положительных примеров можно 
	применить к ним небольшие сдвиги, отражения, повороты, масштабирования
	таким образом увеличим их кол-во в несколько раз не прибегая к ручному труду

	комбинирования "размножения" положительных примеров и бутстраппинга дает сильный результат 

детектор Виоло-Джонса:
	первое увеличение скорости

	прямоугольные фильтры (признаки) - это признаки прямоугольной формы элементы которых либо белые 
	либо черные, причем образованные ими области самого фильтра тоже прямоугольные 
	Value = sum i in white_area of value_i - sum i in black_area of value_i 

	интегральным изображением называют такое изображения значение (x, y) пикселя 
	которого есть сумма всех значений пикселов левее и выше его самого 

	подсчитать его можно за 1 проход храня в кач промежуточного значения для каждого 
	пикселя сумму значений пикселов в строке до него вкл 

	таким образом можно быстро расчитать сумму значений пикселов в прямоугольной области 
	D B
	C A = A - B - C + D 

	таким образом прямоугольный фильтр можно очень быстро применять 

	второе увеличение скорости

	метод бустинг:
		1. получаем несколько классификаторов, которые верно классифицируют с вер-ю > 0.5
		2. на каждом этапе выбираем лучший классификатор, который работал лучше на примерах
		которые были "трудными" для предыдущих
		3. "трудность" это вес примера из об выборки 
		4. общий классификатор есть лин комб слабых 

	алгоритм AdaBoost:
		{h} - слабые классификаторы 
		(x_1, y_1), ..., (x_m, y_m) Y={-1, 1}
		1. D_1(i) = 1/m
		2. for k from 1 to K 
			2.1 обучим h_k с минимальной ошибкой eps_k=Pr[h_k(x_i) != y_i]=sum D_k(i)*(1 if h_k(x_i) * y_i < 0 else 0)
			2.2 вес гипотезы alpha_i = 0.5 ln((1-eps_k)/eps_k), чем больше eps_k тем меньше alpha_i 
			2.3 пересчитаем веса D_k+1(i) = D_k(i) * exp(alpha_i * h_k(x_i) * y_i)
			2.4 нормализуем веса N=sum i of D_k+1(i), D_k+1(i) /= N
		3. H(x) = sign(sum k from 1 to K of alpha_k * h_k(x))

	плюсы:
		1. скорость обучения 
		2. универсальность 
		3. отсутствие параметров 
		4. возможность распараллеливания 
	минусы: 
		1. нужно определить нужное число итераций K 

	в случае изображений слабый классификатор имеет вид 
	h_t(x)= 1 if f_t(x) > theta_t else -1, f_t - прямоугольный признак, theta_t - порог 

	так определяем слабые классификаторы прямоугольными признаками
	то есть на каждом этапе адабуста нужно:
		1. вычислить каждый прямоугольный признак на каждом примере 
		2. выбрать наилучший порог для каждого признака 
		3. выбрать лучший полученный h_t
		4. перевзвесить выборку 

	третье увеличение скорости

	метод каскад
	1. начинаем с простых классификаторов, которые отбрасывают 
	часть отрицательных окон, при этом принимают почти все положительные 
	2. при положительном отклике запускается второй классификатор,
	который менее тривиален и т.д.
	3. при отрицательном отклике на любом уровне вложенности, окно отбраковывается 

	т.о. медленные классификаторы применяются только к некоторым окнам 

	ошибки каскада вычисляются как произведение ошибок каждого уровня 
	
	обучение каскада:
	1. задать значения ошибок обоих родов для каждого этапа 
	2. добавлять признаки пока не будет достигнут заданные уровень
	2.1 понизить порог AdaBoost для макс обнаружения 
	2.2 тестирование на отдельном наборе 
	3. если общий уровень ошибок не достаточно низок добавить новый этап 
	4. ложные обнаружения на текущем этапе использовать как отрицательный 
	пример на следующем (бутстраппинг)

	

















