--------------------------------------------------------------------------------------

машоб - раздел комп. наук, изучающий методы построения алгоритмов,
способных обучаться.

задача машоб:
	Есть обучающая выборка в которой каждый элемент описывается набором признаков x 
	для каждого которого известен ответ у.
	Требуется сконструировать функцию f(x) (решающее правило\классификатор) которая 
	выдает ответ y для любого вектора признаков x 
	Она должна "хорошо" работать на новых данных.


область работы метода = Г - все мн-во объектов на которых работает метод 
решающая ф-ция = F_0 in F - класс решающих ф-ций
Опыт = D = X x Y
целевая ф-ция = T(y, F(x)) (y - предугадываемое свойство)

векторизация - перевод представления о предмете в векторное выражение.
компоненты данного векторы называются фактором или признаком.
нормализация факторов - x` = (x-m)/sigma

бинарная классификация:
	Дана обвыборка X, где (х_i, y_i) in R^m*Y, Y={-1, 1}.
	Объекты не зависимые и взяты с определенным распределением.
	Цель- для всех новых x оценить значение argmax P(y|x).
многоклассовая классификация:
	аналогично только Y={1,...,K}
регрессия:
	Y=R и объекты взяты из неизвестного распределения и нужно оценить argmax E(y|x)
кластеризация:
	даны только векторы признаков, известно что они разбиты по кластерам на основе данной 
	метрики

формально:
	1. будем выбирать функции f из параметрического семейства F
	2. пусть L(f(x), y) - ф-ция потерь 
	3. задача обучения состоит в том, что бы найти набор параметров классификатора f, при котором 
	потери на новых данных будут минимальны 
	4. "метод классификации" = парам. семейство F + алгоритм оценки параметров по обучающей выборке 

эмпирический риск:
	пусть X^m обвыборка, тогда R_emp(f, X^m)=1/m * sum i from 1 to m of L(f(x_i), y_i)
	=> f = argmin f in F of R_emp(f, X^m)

явление переобучения:
	когда гипотеза хорошо описывает не св-ва объектов в целом, а только объектов из обучающей выборки 
	происходит когда: слишком "сложная" модель, шум в данных, плохая обвыборка 

принцип структурной минимизации риска:
	мы должны выбирать самую простую модель из достаточно точных (следствие из теории Вапника-Червоненкиса)
	пусть есть послед. F_1 subset F_2 subset .... subset F_h = F. 
	должны выбрать семейство с минимальной сложностью, но с достаточной точностью

регуляризация - метод добавления некоторых дополнительных ограничений к условию с целью решить некорректно 
поставленную задачу или предотвратить переобучение. 

принцип структурной минимизации риска:
	VC-размерность класса ф-ций F - наибольшее кол-во точек, которое мб разделено 
	ф-циями семейства, вне зависимость от конфигурации мн-ва точек.

	мы должны выбирать самую простую модель из достаточно точных (следствие из теории Вапника-Червоненкиса)
	пусть есть послед. F_1 subset F_2 subset .... subset F_h = F. 
	должны выбрать семейство с минимальной сложностью, но с достаточной точностью

удерживание:
	пусть дана обвыборка с известными ответами 
	разобьем его на две не пересекающиеся части 
	одну часть будем использовать для обучения а другую для контроля 
	=> P(f(x) != y) ~ P(f(x) != y|X_cont)

	св-ва метода:
		1. быстро и просто рассчитывается
		2. некоторые "сложные" векторы признаков могут полностью попасть только в одну из выборок 
		таким образом оценка ошибки будет смещенной 

скользящий контроль:
	разделим обвыборку на d не пресекающихся частей и поочередно будет использовать одно из
	них для контроля а оставшиеся для обучения 
	результат считается как средняя ошибка по всем итерациям 
	св-ва метода:
		1. в пределе равен общему риску 
		2. каждый вектор признаков будет один раз присутствовать в контрольной выборке 
		а так же будет в обучении
		3. некоторые "сложные" векторы признаков могут полностью попасть 
		только в один из сегментов и оценка ошибки будет смещенной

пусть есть основной класс 
ошибка 1 рода - вер-ть принять основной класс за вторичный (пропуск искомого объекта)
ошибка 2 рода - вер-ть принять вторичный класс за основной (принятие искомого объекта за "фон")
 
их важно разделять при несбалансированности классов (когда объектов одного из классов очень мало и 
других кратно больше)


Будем делить выборку на l и t подмножества - на l обучаться на t оценивать

Пусть М это метрика решения мы оптимизируем, F способы решения задачи, Т способы измерения решения
на обвыборке. Тогда оптимизируем имеем 
max T of M(argmax F of T(F, l))(t) - мы хотим получить решение F которое максимизирует М

причем M = argmax T of M(argmax F of T(F, l))(t), если параметры опт не смещены.
однако не всегда на практике формулу выше можно применить.

для построения Т будем исходить из соображений 
1. Т <=> М, усреднение М по всему доступному опыту
2. argmax F of T(F, l) = argmax F of M(F, l),
регрессия по стоимости наблюдения для приближения по Т
принцип макс энтропии
принцип мин описания
3. max T of M(argmax F of T(F, l))(t) - вер-ое моделирование получения М из удобного Т

этап 1:
F_0 = argmax F of 1/n*sum i of m(F(x_i), y_i)
тут М разбито на много м (наблюдений)
+ это естественно 
- надо следить за их независимостью 
- работает только когда нет inf 

этап 2:
A({X}) = f^-1 (1/n sum i of f(x_i)) - стоимость наблюдения 
при этом f(x) = x | log(x) | 1/x
так как они монотонные то оптимизируем:
max sum i of f(x_i)

Совместная вероятность - вер-ть одновременного наступления 
двух событий. p(x) = sum y of p(x, y)
Условная вероятность - вер-ть наступления х если у произошло
р(х, у) = р(х|у)p(y)=p(y|x)*p(x)

=> теорема Байеса p(y|x) = р(х|у)p(y)/p(x)

x и у независимые если p(x, y)=p(y)*p(x)


теорема Байеса p(theta|D) = p(theta)*p(D|theta)/p(D)
theta - параметр модели (те величины что мы обучаем)
D - данные
p(theta) - априорная вер-ть (то о чем "догадываемся"), непрерывное распред вер-ей на [0;1]
p(D|theta) - апостериорная вер-ть, правдоподобие  
p(D)=int p(D|theta)*p(theta) d theta - вер-ть данных, нормировочный коэффициент

f: a -> p(y|x=a) - ф-ция правдоподобия 

гипотеза макс. правдоподобия: theta_ML=argmax theta of p(D|theta)

p(theta|D) prop p(theta)*p(D|theta) - апостериорное распределение
макс. апост. гипотеза: theta_MAP=argmax theta of p(theta|D)=argmax theta of p(theta)*p(D|theta)
 
Байесовские предсказания:
p(x|D) = int p(x, theta | D) d theta = int p(x|theta, D) p(theta|D) d theta = так как D на x не оказывают
влияние если theta уже известно, полагаем = int p(x|theta) p(theta|D) d theta


p(f) - угадывается
p(X|f) = mul i of p(x_i|f) - считаем что точки незав. и одинаково распределенны.

F(x) = int f of p(x|f)*p(f|X) d f - решающая функция 

св-ва Байесовких методов:
плюсы:
все "честно" с точностью до данных и полученной модели 
можно использовать информацию о предыдущем обучении 
можно понять погрешность предсказания 
минусы:
сильная зависимость от выбора p(f)
сложная решающая функция
необходимо эффективно сэмплировать (вычислять F(x))

что бы пофиксить сложность вычислений можно положить самое вер-ое решение:
F(x) = f(x): p(f|X) > p(g|X) for all g in F - maximum posteriori

если нет информации о предыдущих наблюдениях и сложно придумать p(f), то 
можно положить что все решения равно вероятны:
F = argmax F in p(X|f) = argmax F in mul i of p(x_i|f) = argmax F in sum i of log(p(x_i|f))
F = argmax F in sum i of w_i * log(p(x_i|f)), если у примеров различная значимость 
--------------------------------------------------------------------------------------
РЕГРЕССИЯ

это предсказание значения 1+ вещественной переменной на основе вектора х (вектора признаков объекта)

нужно строить решающую ф-цию вида: y(x, w) + eps, где eps некоторая случ величина, может 

виды решающих ф-ций:
1. линейные: y(x, w) = w*x = sum i from 0 to D-1 of w_i*x_i, (w_0 = 1)
2. линейные базисные: y(x, w) = w*phi(x) = sum i from 0 to M-1 of w_i*phi_i(x), (phi_0 = 1)
phi_i(x) = x^i - полиноминальная регрессия 
PHI=|| phi_j(x_i) || - матрица плана

ф-ция правдоподобия:
p(t|X, w, sigma^2) = mul n from 1 to N of N(t_n|w^T*phi(x_n), sigma^2)
p(t|X, w, sigma^2) = mul n from 1 to N of 1/sqrt(2*pi*sigma^2) exp(-(t_n-w^T*phi(x_n))^2/(2*sigma^2))
ln(p(t|X, w, sigma^2)) = N*ln(1/sqrt(2*pi*sigma^2)) + sum n from 1 to N of -(t_n-w^T*phi(x_n))^2/(2*sigma^2) =
N*ln(1/sqrt(2*pi*sigma^2)) - 1/(2*sigma^2) sum n from 1 to N of (t_n-w^T*phi(x_n))^2
E(w)= 1/2 sum n from 1 to N of (t_n-w^T*phi(x_n))^2 - целевая ф-ция лин регрессии 
argmin w of E(w) - оптимальные параметры модели 
grad E(w) = -sum n from 1 to N of (t_n-w^T*phi(x_n))*phi(x_n)
grad E(w)^T = 0^T
sum n from 1 to N of (t_n-w^T*phi(x_n))*phi^T(x_n) = 0^T
t^T * PHI - w^T * PHI^T * PHI = 0^T
w^T = t^T * PHI * (PHI^T * PHI)^-1
w = (PHI^T * PHI)^-1 * PHI^T * t - оптимальные коэффициенты

однако не понятно как не эмпирически подобрать базис (степень полинома например)
решением этой проблемы является регуляризация:
E(w)= 1/2 sum n from 1 to N of (t_n-w^T*phi(x_n))^2 + lambda/2 sum j from 1 to M-1 of |w_j|^q (w_0 не регуляризуется)

при q=2

E(w)= 1/2 sum n from 1 to N of (t_n-w^T*phi(x_n))^2 + lambda/2 * w^T * w
grad E(w) = -sum n from 1 to N of (t_n-w^T*phi(x_n))*phi(x_n) + lambda * w
grad E(w)^T = 0^T
t^T * PHI - w^T * PHI^T * PHI - lambda * w^T = 0^T
w^T * (PHI^T * PHI + lambda * I) = t^T * PHI 
w^T = t^T * PHI * (PHI^T * PHI + lambda * I)^-1
w = (PHI^T * PHI + lambda * I)^-1 * PHI^T * t - оптимальные коэффициенты

вся выборка делится на три множества:
training set 60, 70% - подбор w 
validation set 20, 15% - подбор lambda, phi 
test set 20, 15% - подсчет точности 

замечание: прямое вычисление w по формулам выше адекватно если размерность матрицы плана это позволяет,
иначе используют град. спуск 





